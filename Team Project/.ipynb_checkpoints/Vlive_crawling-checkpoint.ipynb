{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ì‹œê°„ ì „\n",
      "6ì‹œê°„ ì „\n",
      "6ì‹œê°„ ì „\n",
      "6ì‹œê°„ ì „\n",
      "7ì‹œê°„ ì „\n",
      "7ì‹œê°„ ì „\n",
      "7ì‹œê°„ ì „\n",
      "20ì‹œê°„ ì „\n",
      "23ì‹œê°„ ì „\n",
      "2019. 11. 29. ì˜¤ì „ 7:41\n",
      "2019. 11. 29. ì˜¤ì „ 3:27\n",
      "2019. 11. 29. ì˜¤ì „ 3:26\n",
      "2019. 11. 28. ì˜¤í›„ 11:35\n",
      "2019. 11. 28. ì˜¤í›„ 11:33\n",
      "2019. 11. 28. ì˜¤í›„ 11:27\n",
      "2019. 11. 28. ì˜¤í›„ 11:26\n",
      "2019. 11. 28. ì˜¤í›„ 11:26\n",
      "2019. 11. 28. ì˜¤í›„ 11:26\n",
      "2019. 11. 28. ì˜¤í›„ 10:49\n",
      "2019. 11. 28. ì˜¤í›„ 8:44\n",
      "å†¬ãŒè¨ªã‚Œã¾ã—ãŸã­\n",
      "ç•ªçµ„ã§EternallyãŒã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°ã‚½ãƒ³ã‚°ã«ãªã£ã¦å¬‰ã—ã„ã§ã™ğŸ’“MVã‚‚å°‘ã—å…¬é–‹ã•ã‚Œã‚‹ã¿ãŸã„ã§ã™ï¼12æœˆã¯æ¯é€±è¦‹ãªã„ã¨ã§ã™ã­ï¼ï¼\n",
      "ìŠ¹í¬ í‘ë°œ ì—¼ìƒ‰ í•™ìƒ ì—°ê¸° ì™€ìš°\n",
      "https://youtu.be/it5hWzmInCE\n",
      "í€¸ë¤ ì´í›„ë¡œ ë¸Œì´ì•± í™ë³´í–ˆë”ë‹ˆ ì˜¤ëŠ˜ë¡œ 2ë§Œëª… ì¦ê°€~\n",
      "ì™€ í‚¤íŠ¸ê°€ ë„ì°©í–‡ë„¤ìš”\n",
      "https://open.kakao.com/o/gOxb1BKb\n",
      "ë§ì´ ë§ì´ ë“¤ì–´ì˜¤ì„¸ìš”ã…ã…\n",
      "ğŸ‘ğŸ‘\n",
      "Didn't you find it hard to fall in OHMYGIRL because you are poor at Korean?\n",
      "So, we made a chat room for foreign Miracles !!\n",
      "If you have any questions about OHMYGIRL, events, etc. , Korean Miracles will explain kindly.\n",
      "Also, if you want to learn Korean, we'll help you.\n",
      "\n",
      "https://open.kakao.com/o/gJjRkaMb\n",
      "I miss you more today than yesterday! ğŸ˜­â¤ï¸\n",
      "https://open.kakao.com/o/g64WKKHb\n",
      "ë§ì´ ë“¤ì–´ì™€ì£¼ì„¸ìš” ã… ã… \n",
      "ì—¬ëŸ¬ë¶„ë“¤ì„ ìœ„í•œ ì‚¬ì§„\n",
      "ì§€í˜¸ ì—¼ìƒ‰ë¨¸ë¦¬ ì¸ì‚¬\n",
      "https://youtu.be/ug-tXXfpY2k\n",
      "ì™€ ì˜¤ëŠ˜ ì ì•ˆìë„ ë˜ê² ë‹¤\n",
      "ë¯¸ë¼í´ì´ë©´ ë‹¤ë†€ëŸ¬ì™€ìš©~~ ëª¨ë‘ì¹œì ˆí•œ ë¯¸ë¼í´ì´ëë‹ˆëŒ±!! ì˜ˆì˜ê³  ì”…ì²­ë¯¸ë„˜ì¹˜ëŠ” ì”…ì”…ì´~~~\n",
      "ìœ ë ˆì¹´!ì˜¤ë§ˆì´ê±¸ë°©https://open.kakao.com/o/g6ukdKKb\n",
      "ìš°ë¦¬ë“¤ì€ ë¯¸ë¼í´ë°©https://open.kakao.com/o/gOxb1BKb\n",
      "Another Japanese album is coming to us on January 8, 2020. Eternally, I canâ€™t wait to get you. ğŸ˜­â¤ï¸\n",
      "í•˜...ë§ˆì§€ë§‰ê¹Œì§€ ì„¤ë ˆê²Œí•´..ã…œã…œğŸ˜¢â¤\n",
      "ì§§ì€ ë¸¨ì•±ì´ì§€ë§Œ ê·¸ë˜ë„ ê°ì‚¬í•©ë‹ˆë‹¤\n",
      "ì”… ê·€ì—¬ì›Œ~(ê·€ì—¬ì›Œì„œ ë” ì•„ì‰½ë‹¤ ì§§ì•„ ã… )\n",
      "ëŒ“ê¸€ ì½ì–´ì¤˜ì„œ ê³ ë§ˆì›Œ ã…ã…\n",
      "ã‚¹ãƒ³ãƒ’å¯æ„›ã™ãã‚‹â¤\n",
      "ãã—ã¦ã€ãƒ¦ã‚¢ã‹ã‚‰ã‚¹ãƒ³ãƒ’ã«ã½ã£ã½å¯æ„›ã„â¤\n",
      "æ°¸é ã®ç§ã®ãŠå§«æ§˜ã§ã™ğŸ™ˆâ¤ï¸\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "# ì˜¤ë§ˆì´ê±¸ \n",
    "url = \"https://channels.vlive.tv/F51143/fan\" \n",
    "\n",
    "# *** ë“œë¼ì´ë²„ ìœ„ì¹˜ í¬í•¨ ë””ë ‰í† ë¦¬ë¡œ ì´ë™ *** \n",
    "driver = webdriver.Chrome(\"/Users/user/Desktop/chromedriver\")\n",
    "driver.implicitly_wait(3)\n",
    "driver.get(url)\n",
    "time.sleep(1)\n",
    "\n",
    "# http://bongholee.com/2017/06/python-web-crawling%EC%9D%84-%ED%86%B5%ED%95%B4-raw-data-%EA%B5%AC%ED%95%98%EA%B8%B0-selenium-library/\n",
    "elem = driver.find_element_by_tag_name(\"body\")\n",
    "no_of_pagedowns = 1\n",
    "\n",
    "while no_of_pagedowns:\n",
    "    elem.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(0.2)\n",
    "    no_of_pagedowns -= 1\n",
    "    \n",
    "# html = driver.page_source\n",
    "# print(html)\n",
    "# soup = BeautifulSoup(html, \"html.parser\")\n",
    "# date_list = soup.find_all(\"time\", class_=\"day\")\n",
    "# content_list = soup.find_all(\"span\", class_=\"text\")\n",
    "# len(date_list)\n",
    "# print(date.text)\n",
    "# print(content.text)\n",
    "\n",
    "date_list = driver.find_elements_by_xpath(\"//time[@class='day']\")\n",
    "content_list = driver.find_elements_by_xpath(\"//span[@class='text']\")\n",
    "\n",
    "for date in date_list:\n",
    "    print(date.text)\n",
    "\n",
    "for content in content_list:\n",
    "    print(content.text)\n",
    "\n",
    "# len(date_list)\n",
    "# len(content_list)\n",
    "                                       \n",
    "# driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error code(í•´ì„ ë¶ˆê°€)\n",
    "# https://paulhoganreid.wordpress.com/2015/01/19/using-python-and-selenium-to-scrape-an-infinitely-scrolling-table/\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import selenium.webdriver\n",
    "\n",
    "url = \"https://channels.vlive.tv/F51143/fan\" \n",
    "driver = webdriver.Chrome(\"/Users/user/Desktop/chromedriver\")\n",
    "driver.get(url)\n",
    "\n",
    "while driver.find_element_by_xpath(\"//time[@class='day']\").text != '2019. 08. 28.':\n",
    "    elem = driver.find_element_by_tag_name('time')\n",
    "    elem.send_keys(Keys.PAGE_DOWN)\n",
    "    \n",
    "date_list = driver.find_elements_by_xpath(\"//time[@class='day']\")\n",
    "content_list = driver.find_elements_by_xpath(\"//span[@class='text']\")\n",
    "\n",
    "print(len(date_list))\n",
    "print(len(content_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "url = \"https://channels.vlive.tv/F51143/fan\" \n",
    "driver = webdriver.Chrome(\"/Users/user/Desktop/chromedriver\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'web_fetch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-584facf7ba79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://channels.vlive.tv/F51143/fan\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# res = requests.get(url)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweb_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'web_fetch' is not defined"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://channels.vlive.tv/F51143/fan\"\n",
    "res = requests.get(url)\n",
    "data = res.decode('utf-8')\n",
    "dataset = json.loads(data)\n",
    "print(dataset)\n",
    "# data = json.loads(res.content.decode('utf-8'))\n",
    "# print(data)\n",
    "\n",
    "# text = res.json()\n",
    "\n",
    "# pprint.pprint(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
