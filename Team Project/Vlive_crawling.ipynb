{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2시간 전\n",
      "6시간 전\n",
      "6시간 전\n",
      "6시간 전\n",
      "7시간 전\n",
      "7시간 전\n",
      "7시간 전\n",
      "20시간 전\n",
      "23시간 전\n",
      "2019. 11. 29. 오전 7:41\n",
      "2019. 11. 29. 오전 3:27\n",
      "2019. 11. 29. 오전 3:26\n",
      "2019. 11. 28. 오후 11:35\n",
      "2019. 11. 28. 오후 11:33\n",
      "2019. 11. 28. 오후 11:27\n",
      "2019. 11. 28. 오후 11:26\n",
      "2019. 11. 28. 오후 11:26\n",
      "2019. 11. 28. 오후 11:26\n",
      "2019. 11. 28. 오후 10:49\n",
      "2019. 11. 28. 오후 8:44\n",
      "冬が訪れましたね\n",
      "番組でEternallyがオープニングソングになって嬉しいです💓MVも少し公開されるみたいです！12月は毎週見ないとですね！！\n",
      "승희 흑발 염색 학생 연기 와우\n",
      "https://youtu.be/it5hWzmInCE\n",
      "퀸덤 이후로 브이앱 홍보했더니 오늘로 2만명 증가~\n",
      "와 키트가 도착햇네요\n",
      "https://open.kakao.com/o/gOxb1BKb\n",
      "많이 많이 들어오세요ㅎㅎ\n",
      "👍👍\n",
      "Didn't you find it hard to fall in OHMYGIRL because you are poor at Korean?\n",
      "So, we made a chat room for foreign Miracles !!\n",
      "If you have any questions about OHMYGIRL, events, etc. , Korean Miracles will explain kindly.\n",
      "Also, if you want to learn Korean, we'll help you.\n",
      "\n",
      "https://open.kakao.com/o/gJjRkaMb\n",
      "I miss you more today than yesterday! 😭❤️\n",
      "https://open.kakao.com/o/g64WKKHb\n",
      "많이 들어와주세요 ㅠㅠ\n",
      "여러분들을 위한 사진\n",
      "지호 염색머리 인사\n",
      "https://youtu.be/ug-tXXfpY2k\n",
      "와 오늘 잠안자도 되겠다\n",
      "미라클이면 다놀러와용~~ 모두친절한 미라클이랍니댱!! 예쁘고 씅청미넘치는 씅씅이~~~\n",
      "유레카!오마이걸방https://open.kakao.com/o/g6ukdKKb\n",
      "우리들은 미라클방https://open.kakao.com/o/gOxb1BKb\n",
      "Another Japanese album is coming to us on January 8, 2020. Eternally, I can’t wait to get you. 😭❤️\n",
      "하...마지막까지 설레게해..ㅜㅜ😢❤\n",
      "짧은 븨앱이지만 그래도 감사합니다\n",
      "씅 귀여워~(귀여워서 더 아쉽다 짧아 ㅠ)\n",
      "댓글 읽어줘서 고마워 ㅎㅎ\n",
      "スンヒ可愛すぎる❤\n",
      "そして、ユアからスンヒにぽっぽ可愛い❤\n",
      "永遠の私のお姫様です🙈❤️\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "# 오마이걸 \n",
    "url = \"https://channels.vlive.tv/F51143/fan\" \n",
    "\n",
    "# *** 드라이버 위치 포함 디렉토리로 이동 *** \n",
    "driver = webdriver.Chrome(\"/Users/user/Desktop/chromedriver\")\n",
    "driver.implicitly_wait(3)\n",
    "driver.get(url)\n",
    "time.sleep(1)\n",
    "\n",
    "# http://bongholee.com/2017/06/python-web-crawling%EC%9D%84-%ED%86%B5%ED%95%B4-raw-data-%EA%B5%AC%ED%95%98%EA%B8%B0-selenium-library/\n",
    "elem = driver.find_element_by_tag_name(\"body\")\n",
    "no_of_pagedowns = 1\n",
    "\n",
    "while no_of_pagedowns:\n",
    "    elem.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(0.2)\n",
    "    no_of_pagedowns -= 1\n",
    "    \n",
    "# html = driver.page_source\n",
    "# print(html)\n",
    "# soup = BeautifulSoup(html, \"html.parser\")\n",
    "# date_list = soup.find_all(\"time\", class_=\"day\")\n",
    "# content_list = soup.find_all(\"span\", class_=\"text\")\n",
    "# len(date_list)\n",
    "# print(date.text)\n",
    "# print(content.text)\n",
    "\n",
    "date_list = driver.find_elements_by_xpath(\"//time[@class='day']\")\n",
    "content_list = driver.find_elements_by_xpath(\"//span[@class='text']\")\n",
    "\n",
    "for date in date_list:\n",
    "    print(date.text)\n",
    "\n",
    "for content in content_list:\n",
    "    print(content.text)\n",
    "\n",
    "# len(date_list)\n",
    "# len(content_list)\n",
    "                                       \n",
    "# driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error code(해석 불가)\n",
    "# https://paulhoganreid.wordpress.com/2015/01/19/using-python-and-selenium-to-scrape-an-infinitely-scrolling-table/\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import selenium.webdriver\n",
    "\n",
    "url = \"https://channels.vlive.tv/F51143/fan\" \n",
    "driver = webdriver.Chrome(\"/Users/user/Desktop/chromedriver\")\n",
    "driver.get(url)\n",
    "\n",
    "while driver.find_element_by_xpath(\"//time[@class='day']\").text != '2019. 08. 28.':\n",
    "    elem = driver.find_element_by_tag_name('time')\n",
    "    elem.send_keys(Keys.PAGE_DOWN)\n",
    "    \n",
    "date_list = driver.find_elements_by_xpath(\"//time[@class='day']\")\n",
    "content_list = driver.find_elements_by_xpath(\"//span[@class='text']\")\n",
    "\n",
    "print(len(date_list))\n",
    "print(len(content_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "url = \"https://channels.vlive.tv/F51143/fan\" \n",
    "driver = webdriver.Chrome(\"/Users/user/Desktop/chromedriver\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-b8e9a525c8ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# text = res.json()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "# import requests\n",
    "import urllib.request\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://channels.vlive.tv/F51143/fan\"\n",
    "res = requests.get(url)\n",
    "# text = res.json()\n",
    "\n",
    "# data = res.decode('utf-8')\n",
    "# dataset = json.loads(data)\n",
    "# print(dataset)\n",
    "\n",
    "# data = json.loads(res.content.decode('utf-8'))\n",
    "# print(data)\n",
    "\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    print(data)\n",
    "# text = res.json()\n",
    "\n",
    "# pprint.pprint(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
