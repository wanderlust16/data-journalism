{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 - Data Analysis Using NumPy and Pandas 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas를 사용하기 위해서 다음과 같이 라이브러리를 import 한다. numpy도 주로 같이 사용하니 같이 import 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas는 read_csv()라는 CSV 파일을 읽어주는 함수를 제공한다.\n",
    "\n",
    "(참고) Excel 파일을 읽는 함수도 제공한다. ExcelFile(), read_excel()\n",
    "* df = pd.ExcelFile(\"dummydata.xlsx\")\n",
    "* df = pd.read_excel(open('your_xls_xlsx_filename','rb'), sheetname='Sheet 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/weather_year.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns 명령어는 데이터의 column을 보여준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 column을 읽어오려면 다음과 같이 쓴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['EDT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어레이를 이용하여 여러개의 column을 불러올 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['EDT', 'Max TemperatureF', 'Mean TemperatureF']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "describe() 명령어는 기초 통계값을 보여준다. 숫자에만 적용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['EDT', 'Max TemperatureF', 'Mean TemperatureF']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 column 이름에 공백이 없다면, **```data.column_name```** 형태로 표현 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.EDT # only works when the column name has no space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "head()는 다섯개의 샘플 데이터만 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.head(num)는 원하는 수 num 만큼의 데이터를 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['EDT', 'Max TemperatureF', 'Mean TemperatureF']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tail() 함수는 head()와 반대로 맨 아래 다섯개의 데이터를 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['EDT', 'Max TemperatureF', 'Mean TemperatureF']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다시 columns 를 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns는 단어 중간이나 앞부분에 공백이 있기도 하고 길어서 데이터 처리에 불편하다. columns를 다음과 같이 고쳐보자. column들의 이름이 바뀌었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [\"date\", \"max_temp\", \"mean_temp\", \"min_temp\", \"max_dew\",\n",
    "                \"mean_dew\", \"min_dew\", \"max_humidity\", \"mean_humidity\",\n",
    "                \"min_humidity\", \"max_pressure\", \"mean_pressure\",\n",
    "                \"min_pressure\", \"max_visibilty\", \"mean_visibility\",\n",
    "                \"min_visibility\", \"max_wind\", \"mean_wind\", \"min_wind\",\n",
    "                \"precipitation\", \"cloud_cover\", \"events\", \"wind_dir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.min_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.min_temp.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas는 자체적으로 matplotlib을 지원하고 있다. 따라서 간단하게 데이터의 그래프를 그릴 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebook에서 그래프를 보이게 하려면 다음과 같은 명령어를 입력한다.\n",
    "\n",
    "`%matplotlib inline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# 아래의 코드에서 실제로 plt 는 사용하지 않지만, 후에 matplotlob.pyplot를 이용해 그림을 그린다면 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.min_temp.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.min_temp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk Data Clean Up\n",
    "\n",
    "이번에는 apply()함수를 사용하여 column 내의 데이터를 한꺼번에 변경하는 방법을 다룬다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_date = data.date.values[0]\n",
    "type(first_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지난 번에 사용했던 방법으로 str 오브젝트를 datetime 오브젝트로 변환해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "datetime.strptime(first_date, \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lambda와 apply()를 사용해서 데이터의 형을 변환한다. apply()는 bulk operation을 가능하게 한다. 즉, column에 있는 모든 요소에 한꺼번에 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (참고) lambda 의 사용법\n",
    "function = lambda x: x*5\n",
    "function(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.date = data.date.apply(lambda d: datetime.strptime(d, \"%Y-%m-%d\"))\n",
    "data.date.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 우리 데이터의 각각의 row의 index는 0 ~ len(data)의 integer가 자동으로 지정되었다. 만약 데이터의 index를 다른 컬럼으로 (예를 들어 date) 지정하고 싶으면 index 명령어를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = data.date\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 데이터를 날짜를 이용해서 검색할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[datetime(2012, 8, 22)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불필요한 컬럼을 삭제하기 위해서는 drop() 명령어를 사용한다. 위의 데이터에서는 date를 index로 지정하였기 때문에 데이터 테이블 내의 date는 필요없다. (현재 중복되어 있다) \n",
    "\n",
    "다음과 같이 삭제할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"date\"], axis=1)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "axis=1 은 column에 적용됨을 의미한다. 0은 row에 1은 column에 적용된다고 생각하면 된다. \n",
    "http://stackoverflow.com/questions/25773245/ambiguity-in-pandas-dataframe-numpy-array-axis-definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "\n",
    "지난 시간 살펴보았던 데이터처럼 이 데이터에도 missing value 가 있다. missing value 를 처리해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = data.apply(lambda col: pd.isnull(col))\n",
    "empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty.events.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.events.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(empty[empty.events == True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "missing data를 처리하는 한가지 방법은 해당 데이터 포인트를 삭제하는 것. pandas에는 dropna()라는 함수가 있다. 이 함수를 사용하면 데이터가 입력되지 않은 row, 즉 위의 데이터에서 events가 NaN인 경우 모두 삭제를 한다. 그러나, 이렇게 삭제를 하게되면 전체 366개의 데이터 중 162개 밖에 남지 않는다. 따라서 이렇게 missing data가 많은 경우 삭제하는 것 보다는 다르게 처리하는 편이 낫다. 우리는 NaN 대신 빈 문자열을 채워 넣으려고 한다. 이때 사용하는 함수는 fillna()이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.events = data.events.fillna(\"\")\n",
    "data.events.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[3:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[datetime(2012, 3, 15)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterrows()함수는 데이터프레임의 row를 iterate하게 한다. (for loop를 이용하여 한 row 씩 처리하게 한다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rain = 0\n",
    "for idx, row in data.iterrows():\n",
    "    if \"Rain\" in row[\"events\"]:\n",
    "        num_rain += 1\n",
    "\n",
    "\"Days with rain: {0}\".format(num_rain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "Filtering은 데이터를 살펴보고 분석을 할 때 가장 좋은 방법이다. Filtering을 하기 위한 방법들을 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freezing_days = data[data.max_temp <= 32]\n",
    "freezing_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freezing_days[freezing_days.min_temp >= 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data.max_temp <= 32) & (data.min_temp >= 20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필터를 변수 형태로 만들어 놓고 사용하는 것도 물론 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_temp 가 32보다 작거나 같은 경우의 필터를 생성\n",
    "temp_max = data.max_temp <= 32\n",
    "temp_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[temp_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_temp 가 20보다 크거나 같은 경우의 필터를 생성\n",
    "temp_min = data.min_temp >= 20\n",
    "temp_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_min & temp_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_min | temp_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두개의 필터를 이용해서 새로운 필터를 만들어 둘 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_both = temp_min & temp_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "숫자가 아닌 경우는 filter를 이런 식으로 쓸 수 없다. 다음과 같은 코드는 data.events의 각 row를 iterate하며 Rain이 포함되어 있는지 여부를 판단할 것 같지만 그렇지 않다. 이 코드는 에러를 발생한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Rain\" in data.events]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 경우, 다음과 같이 lambda 함수와 apply 함수를 사용해 filter를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.events.apply(lambda e: \"Rain\" in e)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping\n",
    "\n",
    "apply()만큼 유용하게 쓸 수 있는 함수 중에 groupby()가 있다. 이 함수는 dataframe에서 같은 값을 갖는 데이터 포인트를 찾아서 묶어 준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어 cloud_cover 데이터를 추출하면 다음과 같이 0-8까지 값이 기록되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cloud_cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cloud_cover.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data.groupby(\"cloud_cover\"):\n",
    "    print(d)\n",
    "\n",
    "# 결과는 tuple 형태로 출력된다. \n",
    "# d[0] -> cloud_cover level\n",
    "# d[1] -> 각 cloud_cover level이 포함된 data row\n",
    "# 여기서 loop는 각 data row의 iteration을 가져오는게 아니라 group의 iteration을 가져온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출력되는 tuple 값을 이용해서 각 그룹의 평균온도(mean_temp)의 평균을 다음과 같이 구할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_temps = {}\n",
    "for cover, cover_data in data.groupby(\"cloud_cover\"):\n",
    "    cover_temps[cover] = cover_data.mean_temp.mean()\n",
    "cover_temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한개 이상의 컬럼을 이용해서 데이터를 groupby 할 수 있다. 이 경우, 두개의 컬럼의 값이 tuple 로 먼저 출력되고, 그 다음에 data row 가 출력된다.\n",
    "\n",
    "```예) a = ((1,2),3)\n",
    "a[0] => (1,2)\n",
    "a[1] => 3\n",
    "a[0][0] = 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (cover, events), group_data in data.groupby([\"cloud_cover\", \"events\"]):\n",
    "    print(\"Cover: {}, Events: {}, Count: {}\".format(cover, events, len(group_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding New Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "events 컬럼의 데이터를 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.events.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 데이터가 있지만, 기본적으로는 rain, thunderstorm, fog, snow 의 네가지의 조합이다. 특정일에 비가 왔는지, 안개가 끼었는지 등을 확인하고 싶어서 새롭게 컬럼을 만들고자 한다. rain, thunderstorm, fog, snow의 컬럼을 만들고 True or False를 저장할 것이다. (One Hot Coding)\n",
    "* Rain-Thunderstorm => rain:True, thunderstorm:True, fog:False, snow:False\n",
    "* Fog-Rain-Thunderstorm => rain:False, thunderstorm:True, fog:True, snow:False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event_kind in [\"Rain\", \"Thunderstorm\", \"Fog\", \"Snow\"]:\n",
    "    col_name = event_kind.lower()  # Turn \"Rain\" into \"rain\", etc.\n",
    "    data[col_name] = data.events.apply(lambda e: event_kind in e)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rain.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.rain & data.snow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toCel(degree):\n",
    "    return (degree - 32) / 1.8\n",
    "    \n",
    "data[\"max_tempc\"] = data.max_temp.apply(lambda e: toCel(e))\n",
    "data[\"min_tempc\"] = data.min_temp.apply(lambda e: toCel(e))\n",
    "data[\"mean_tempc\"] = data.mean_temp.apply(lambda e: toCel(e))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.mean_tempc.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.mean_tempc.tail(10).plot(kind=\"bar\", rot=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음의 그래프는 여러개 데이터의 그래프를 그려준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data.max_temp.plot(title=\"Min and Max Temperatures\")\n",
    "data.min_temp.plot(style=\"red\")\n",
    "data.mean_temp.plot(style=\"yellow\")\n",
    "ax.set_ylabel(\"Temperature (F)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data\n",
    "\n",
    "to_csv() 함수는 데이터프레임을 CSV형태로 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/weather-mod.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 1\n",
    "* 주어진 employment.csv파일은 header가 없는 파일이다. 불러온 후 column의 header를 추가한다.\n",
    "* 국가명을 인덱스로 지정한다.\n",
    "* 불필요한 컬럼이 있으면 삭제한다.\n",
    "* 상위 5개를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "employment = pd.read_csv(\"data/gapminder/employment.csv\", header=None)\n",
    "employment.columns = [\"country\", \"employment\"]\n",
    "employment.index = employment.country\n",
    "employment = employment.drop(['country'], axis=1)\n",
    "employment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 2\n",
    "* 나머지 2개의 파일은 비슷한 구조로 되어 있어 employment.csv와 유사한 방법으로 불러오게 된다. 함수를 만들고 나머지 파일을 불러오자.\n",
    "* life_expectancy.csv\n",
    "* gdp_per_capita.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gapminder_data(filename, colname):\n",
    "    data = pd.read_csv(\"data/gapminder/{}\".format(filename), header=None)\n",
    "    data.columns = [\"country\", colname]\n",
    "    data.index = data.country\n",
    "    data = data.drop(['country'], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "life_exp = read_gapminder_data(\"life_expectancy.csv\", \"life_exp\")\n",
    "life_exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = read_gapminder_data(\"gdp_per_capita.csv\", \"gdp\")\n",
    "gdp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 3\n",
    "* 세개의 데이터프레임을 하나로 합치자.\n",
    "* 데이터프레임을 합칠 때는 merge, join 등의 개념이 사용된다.\n",
    "* http://pandas.pydata.org/pandas-docs/stable/merging.html 를 참고하자.\n",
    "* (힌트) concat 이 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [employment, life_exp, gdp]\n",
    "gm_data = pd.concat(frames, axis=1)\n",
    "gm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "소팅을 해보자. 소팅은 다음과 같이 한다.\n",
    "* data.sort_values([colname1, colname2, ...], ascending=[True, False, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_data.sort_values(['gdp', 'employment'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 4\n",
    "* 전체 데이터프레임의 기술통계값을 출력하고 그래프를 그려보자.\n",
    "* employment와 life_exp의 histogram을 그려보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gm_data.employment.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_data.life_exp.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 5-1\n",
    "* employment rate이 가장 높은 나라와 가장 낮은 나라의 이름과 값을 출력하자.\n",
    "* 구글검색 혹은 레퍼런스를 통해 가장 높은 값과 낮은 값을 가진 인덱스를 출력하는 함수를 찾아 적용해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Employment Rate이 가장 높은 나라는 {}이고 값은 {}이다.\".format(gm_data.employment.idxmax(), gm_data.employment.max()))\n",
    "print(\"Employment Rate이 가장 낮은 나라는 {}이고 값은 {}이다.\".format(gm_data.employment.idxmin(), gm_data.employment.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 5-2\n",
    "* gdp 상위 10개 국가의 평균과 하위 10개 국가의 리스트와 값을 구하고 그리고 평균의 차이를 구해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_gdp = gm_data.sort_values(['gdp'], ascending=False)[0:10]\n",
    "bottom10_gdp = gm_data.sort_values(['gdp'], ascending=True)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_gdp.gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom10_gdp.gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_gdp_diff = top10_gdp.gdp.mean() - bottom10_gdp.gdp.mean()\n",
    "print(\"두 그룹 간 평균의 차이는 {}이다.\".format(mean_gdp_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 5-3\n",
    "* gpd 상위 10개 국가의 기대수명과 취업률 평균을 구하고 하위 10개 국가의 기대수명과 취업률 평균과 비교해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GDP 상위 10개 국가의 기대수명 평균은 {}세, 취업률은 {}% 이다.\".format(top10_gdp.life_exp.mean(), top10_gdp.employment.mean()))\n",
    "print(\"GDP 하위 10개 국가의 기대수명 평균은 {}세, 취업률은 {}% 이다.\".format(bottom10_gdp.life_exp.mean(), bottom10_gdp.employment.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 6-1\n",
    "* 각 국가의 초등학교 수료율을 기록한 두개의 파일을 읽어 하나의 데이터프레임을 만들어 보자.\n",
    "* 남자의 초등학교 수료율: male_completion_rate.csv\n",
    "* 여자의 초등학교 수료율: female_completion_rate.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_comp = read_gapminder_data(\"male_completion_rate.csv\", \"male_comp\")\n",
    "female_comp = read_gapminder_data(\"female_completion_rate.csv\", \"female_comp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [male_comp, female_comp]\n",
    "school_comp = pd.concat(frames, axis=1)\n",
    "school_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 6-2\n",
    "* 초등학교 수료율이 남성보다 여성이 더 높은 나라를 찾아보자.\n",
    "* 초등학교 수료율이 여성보다 남성이 더 높은 나라를 찾아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_comp[\"male_comp_greater\"] = school_comp.apply(lambda row: (row['male_comp'] >= row['female_comp']), axis=1)\n",
    "school_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_comp[school_comp.male_comp_greater==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_comp[school_comp.male_comp_greater==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 6-3\n",
    "* 남성과 여성 간의 초등학교 수료율 차이가 큰 상위 20개의 나라를 찾아보자. (Top10 vs Botton10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_comp[\"difference\"] = school_comp.apply(lambda row: (row['male_comp'] - row['female_comp']), axis=1)\n",
    "school_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_female_greater = school_comp.sort_values(['difference'], ascending=True)[0:10]\n",
    "top10_female_greater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_male_greater = school_comp.sort_values(['difference'], ascending=False)[0:10]\n",
    "top10_male_greater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
